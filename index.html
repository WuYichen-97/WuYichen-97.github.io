<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN" "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="files/jemdoc.css" type="text/css" />

<title>Hong Wang</title>

</head>
<body>

<a id="home" class="anchor"></a>
<div id="container"> 
<div class="container"> 

<table class="imgtable">
<tr>
<td> <a href="./"><img src="./Figures/Hong.png" alt="" height="200px" /></a>&nbsp;</td>
<td align="left">
<p>
<font size="4">Hong Wang (王 红)</font><br />
<br />
<a href="https://jarvislab.tencent.com/" target="_blank" rel="noopener noreferrer">Jarvis Lab@Tencent</a><br />
<br />
    Tencent Building, Shennan Avenue, ShenZhen, China<br />
<br />
Email: hazelhwang@tencent.com
<br />
[<a class="p1" href="https://scholar.google.com/citations?user=I5RH0CwAAAAJ&amp;hl=en" target="_blank">Google Scholar</a>]
[<a class="p2" href="https://github.com/hongwang01" target="_blank">Github</a>]
[<a href="https://www.researchgate.net/profile/Hong-Wang-150" target="_blank">ResearchGate</a>]
[<a href="http://www.linkedin.com/in/hwang~DL" target="_blank">Linkedin</a>]
</p>
</td>
</tr></table>

<h2>Biography</h2>
<p> I am currently a researcher at Tencent, ShenZhen,
    working with Dr. <a href="https://sites.google.com/site/yefengzheng/" target="_blank">Yefeng Zheng (IEEE Fellow)</a>.
    I received my Ph.D. degree from School of Mathematics and Statistics, Xi'an Jiaotong University, China, in 2021, 
    under the supervision of Prof. <a href="https://gr.xjtu.edu.cn/en/web/dymeng" target="_blank">Deyu Meng</a>.
    Before that, I received my M.Sc degree under the supervision of <a href="https://person.zju.edu.cn/en/zhaoyangzhang/">Prof. Zhaoyang Zhang </a>from
    School of Information and Electronical Engineer, Zhejiang University, in 2018, and the B.S. degree from School of Communication and
    Information Engineer, Nanjing University of Posts and Telecommunications, in 2015.
  </p>


<h2>Research Interest</h2>
Currently, my work focus on medical image analysis and natural image restoration. Specifically, I mainly investigate how to combine model-driven and data-driven techniques for effective and interpretable image
restoration/reconstruction. Recently, I focus on the following research topics:
<ul>
<li>Deep Unfolding Image Restoration</li>
<li>Bayesian methods in image processing</li>
<li>Natural Image Restoration (such as, derain/super-resolution/denoise/deblur/low-light enhancement) </li>
<li>CT Reconstruction (such as, metal artifact reduction/low-dose/spare-view/limited-angle)</li>
<li>MRI Reconstruction (such as, fast imaging/super-resolution/multi-contrast reconstruction)</li>
<li>Other Medical Image Analysis (including classification/segmentation/detection)</li>
</ul>


<h2>Research Experiences</h2>
<table class="imgtable">
<tr>
    <td align="left">
            <img src="./Figures/Tencent.jpg" alt="" height="40px" width="110px"/>
    </td>
    <td>
        <p><a href="https://jarvislab.tencent.com/" target="_blank" rel="noopener noreferrer">Jarvis Lab@Tencent</a>, ShenZhen, China</p>
        <p>Researcher, Feb. 2022 ~ present</p>
        <p>Supervisor: Dr. <a style="color:Purple" href="https://sites.google.com/site/yefengzheng/" target="_blank">Yefeng Zheng</a></p>
    </td>
</tr>
<tr>
    <td align="left">
            <img src="./Figures/Tencent.jpg" alt="" height="110px" width="110px"/>
    </td>
    <td>
        <p><a href="https://jarvislab.tencent.com/" target="_blank" rel="noopener noreferrer">Jarvis Lab@Tencent</a>, ShenZhen, China</p>
        <p>Research Intern, Sep. 2020 ~ Jan. 2022</p>
        <p>Supervisor: Dr. <a style="color:Purple" href="https://sites.google.com/site/yefengzheng/" target="_blank">Yefeng Zheng</a></p>
    </td>
</tr>

</table>



<!-- Project -->
<a id="publications" class="anchor"></a>
<h2>Selected Publications
<a style="color:Black" class="p1" href="https://scholar.google.com/citations?user=I5RH0CwAAAAJ&amp;hl=en" target="_blank">
    <font size="2"> [Full List]</font></a>
</h2>

<table class="imgtable">

<!--MedIA 2021-->
<tr>
<td><img class="proj_thumb" src="./Figures/InDuDoNet+_MedIA2022.png" alt="" height="100px"/>&nbsp;</td>
<td>
<p class="pub_title">InDuDoNet+: A Model-Driven Interpretable Dual Domain Network for CT Metal Artifact Reduction </p>
<p class="pub_author"><b>Hong Wang</b>, Yuexiang Li, Haimiao Zhang, Kai Ma, Deyu Meng, and Yefeng Zheng<br>
Medical Image Analysis (Major Revision)</i>(<b>MedIA</b>), 2021.<br>
[<a href= "https://arxiv.org/pdf/2112.12660.pdf" target="_blank">Paper</a>]
[<a href="https://github.com/hongwang01/InDuDoNet_plus" target="_blank">Code</a>]
</p> </td>
</tr>


<!-- MICCAI 2022, OSCNet-->
<tr>
<td><img class="proj_thumb" src="./Figures/OSCNet_MICCAI2022.png" alt="" height="100px"/>&nbsp;</td>
<td>
<p class="pub_title">Orientation-Shared Convolution Representation for CT Metal Artifact Learning</p>
<p class="pub_author"><b>Hong Wang</b>, Qi Xie, Yuexiang Li, Yawen Huang, Deyu Meng, Yefeng Zheng<br>
International Conference on Medical Image Computing and Computer Assisted Intervention (<b>MICCAI</b>), 2022.<br>
[<a href= "   " target="_blank">Paper</a>]
[<a href="https://github.com/hongwang01/OSCNet" target="_blank">Code</a>]
</p> </td>
</tr>



<!-- IJCAI 2022, ACDNet-->
<tr>
<td><img class="proj_thumb" src="./Figures/ACDNet_IJCAI2022.png" alt="" height="100px"/>&nbsp;</td>
<td>
<p class="pub_title">Adaptive Convolutional Dictionary Network for CT Metal Artifact Reduction</p>
<p class="pub_author"><b>Hong Wang</b>, Yuexiang Li, Deyu Meng, Yefeng Zheng<br>
31st International Joint Conference on Artificial Intelligence (<b>IJCAI</b>), 2022.<br>
[<a href= "https://arxiv.org/pdf/2205.07471.pdf" target="_blank">Paper</a>]
[<a href="https://github.com/hongwang01/ACDNet" target="_blank">Code</a>]
</p> </td>
</tr>


<!-- TMI 2021, DICDNet-->
<tr>
<td><img class="proj_thumb" src="./Figures/DICDNet_TMI2021.png" alt="" height="100px"/>&nbsp;</td>
<td>
<p class="pub_title">DICDNet: Deep Interpretable Convolutional Dictionary Network for Metal Artifact Reduction in CT Images</p>
<p class="pub_author"><b>Hong Wang</b>, Yuexiang Li, Nanjun He, Kai Ma, Deyu Meng, and Yefeng Zheng<br>
IEEE Transactions on Medical Imaging (<b>TMI</b>), 2021.<br>
[<a href= "https://github.com/hongwang01/DICDNet" target="_blank">Paper</a>]
[<a href="https://github.com/hongwang01/DICDNet" target="_blank">Code</a>]
</p> </td>
</tr>


<!-- MICCAI 2021, InDuDoNet-->
<tr>
<td><img class="proj_thumb" src="./Figures/InDuDoNet_MICCAI2021.png" alt="" height="100px"/>&nbsp;</td>
<td>
<p class="pub_title"> </p>
<p class="pub_author"><b>Hong Wang</b>, Yuexiang Li, Haimiao Zhang, Kai Ma, Deyu Meng, and Yefeng Zheng<br>
International Conference on Medical Image Computing and Computer Assisted Intervention  (<b>MICCAI</b>), 2021.<br>
[<a href= "https://arxiv.org/pdf/2109.05298.pdf" target="_blank">Paper</a>]
[<a href="https://github.com/hongwang01/InDuDoNet" target="_blank">Code</a>]
</p> </td>
</tr>


<!-- CVPR 2021, VRGNet-->
<tr>
<td><img class="proj_thumb" src="./Figures/VRGNet_CVPR2021.png" alt="" height="100px"/>&nbsp;</td>
<td>
<p class="pub_title">From Rain Generation to Rain Removal</p>
<p class="pub_author"><b>Hong Wang*</b>, Zongsheng Yue*, Qi Xie, Qian Zhao, Yefeng Zheng, Deyu Meng (*Equal Contribution)<br>
IEEE International Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>), 2021.<br>
[<a href= "https://arxiv.org/pdf/2008.03580.pdf" target="_blank">Paper</a>] 
[<a href="https://github.com/hongwang01/VRGNet" target="_blank">Code</a>] 
</p> </td>
</tr>

<!-- CVPR 2020, RCDNet-->
<tr>
<td><img class="proj_thumb" src="./Figures/RCDNet_CVPR2020.png" alt="" height="100px"/>&nbsp;</td>
<td>
<p class="pub_title">A Model-driven Deep Neural Network for Single Image Rain Removal</p>
<p class="pub_author"><b>Hong Wang</b>, Qi Xie, Qian Zhao, and Deyu Meng<br>
IEEE International Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>), 2020.<br>
[<a href= "https://openaccess.thecvf.com/content_CVPR_2020/html/Wang_A_Model-Driven_Deep_Neural_Network_for_Single_Image_Rain_Removal_CVPR_2020_paper.html" target="_blank">Paper</a>]
[<a href="https://github.com/hongwang01/RCDNet" target="_blank">Code</a>]
</p> </td>
</tr>

<!-- KBS 2021 SRNet-->
<tr>
<td><img class="proj_thumb" src="./files/DANet_ECCV2020.png" alt="" height="100px"/>&nbsp;</td>
<td>
<p class="pub_title">Dual Adversarial Network: Toward Real-World Noise Removal and Noise Generation</p>
<p class="pub_author"><b>Hong Wang</b>, Yichen Wu, Qi Xie, Qian Zhao, Yong Liang, Shijun Zhang, and Deyu Meng<br>
European Conference on Computer Vision</i> (<b>ECCV</b>), 2020.<br>
[<a href= "https://arxiv.org/pdf/2005.09228.pdf" target="_blank">Paper</a>]
[<a href="https://github.com/zsyOAOA/DANet" target="_blank">Code</a>]
</p> </td>
</tr>


<!--SCIS 2022 Survey-->
<tr>
<td><img class="proj_thumb" src="./Figures/Survey_SCIS2022.png" alt="" height="100px"/>&nbsp;</td>
<td>
<p class="pub_title">A Survey on Rain Removal from Video and Single Image</p>
<p class="pub_author"><b>Hong Wang</b>,  Yichen Wu, Minghan Li, Qian Zhao, and Deyu Meng<br>
SCIENCE CHINA Information Sciences</i>(<b>SCIS</b>), 2022.<br>
[<a href= "https://arxiv.org/pdf/1909.08326" target="_blank">Paper</a>]
[<a href="https://github.com/hongwang01/Video-and-Single-Image-Deraining" target="_blank">Code</a>]
</p> </td>
</tr>

<!--TNNLS 2021-->
<tr>
<td><img class="proj_thumb" src="./Figures/DRCDNet_TNNLS2022.png" alt="" height="50px"/>&nbsp;</td>
<td>
<p class="pub_title">Robust Multiview Subspace Learning With Nonindependently and Nonidentically Distributed Complex Noise</p>
<p class="pub_author"><b>Zongsheng Yue</b>, Hongwei Yong, Deyu Meng, Qian Zhao, Yee Leung, Lei Zhang<br>
IEEE International Conference on Neural Networks and Learning Systems</i> (<b>TNNLS</b>), 2019.<br>
[<a href= "https://github.com/zsyOAOA/NIID-MSL/blob/master/paper_TNNLS2019_NIIDMSL.pdf" target="_blank">Paper</a>] 
[<a href="https://github.com/zsyOAOA/NIID-MSL" target="_blank">Code</a>] 
[<a href="https://github.com/zsyOAOA/NIID-MSL/blob/master/supp-TNNLS2019_NIIDMSL.pdf" target="_blank">Supp</a>]
</p> </td>
</tr>



<table>


<!--Honors -->
<a id="honors" class="anchor"></a>
<h2>Honors</h2>
<p>2018.09-2021.12 (Xi'an Jiaotong University): </p>
<font size="2">
<ul>
<li>Outstanding Graduate Student of Shaanxi Province</li>
<li>National Scholarship for Graduate Students (<2%) (<b>highest national wide scholarship for students in China</b>)</li>
<li>Academic star best Popularity Award(<b>Top1 in Xi'an Jiaotong University</b>)</li>
<li>Academic star nomination award (<b>Top13 in Xi'an Jiaotong University</b>)</li>
<li>2nd size for Tencent Rhino Bird Elite Talent(<0.1%), Best Style Award(<0.1%)</li>
<li>Huawei Scholarship (<1%)</li>
<li>Outstanding graduate student of Xi’an Jiaotong University(<b>2 times</b>)</li>
<li>1st size for Scholarship of Xi’an Jiaotong University</li>
<li>3rd size for National Graduate Mathematical modeling Contest (<5%)</li>
<li>Tencent Rhino Bird Elite Talent Program</li>
</ul>
</font>

<p>2015.09-2018.03 (Zhejiang University): </p>
<font size="2">
<ul>
<li>Outstanding graduate student of Zhejiang University</li>
<li>National Scholarship for Graduate Students (<2%) (<b>highest national wide scholarship for students in China</b>)</li>
<li>Outstanding Graduate Student Cadre of Zhejiang University</li>
<li>Merit Graduate Student of Zhejiang University(<b>2 times</b>)</li>
<li>Samsung Scholarship (<3%)</li>
<li>1st size for National Graduate Electronical Design Competition (<1%)</li>
</ul>
</font>

<p>2011.09-2015.06 (Nanjing University of Post and Telecommunications): </p>
<font size="2">
<ul>
<li>Outstanding undergraduate student of NUPT</li>
<li>National Scholarship for Undergraduate Students (<1%, <b>3 times</b>) (<b>highest national wide scholarship for students in China</b>)</li>
<li>China Telecom Scholarship (<1%)</li>
<li>Hengtong First Prize Scholarship (<1%)</li>
<li>1st size (Meritorious Winner) of International Mathematical Contest in Modeling (MCM) (<1%)</li>
<li>Provincial Merit Student Award (<1%)</li>
<li>Pacemaker to Creative Student of NUPT(<b>Top10 in NUPT</b>)</li>
<li>1st size for Advanced Mathematics Competition in Jiangsu Province (<5%)</li>
<li>1st size for scholarship of NUPT (<5%, <b>3 times</b>)</li>
<li>Pacemaker to Merit Student of NUPT (<5%, <b>3 times</b>)</li>
</ul>
</font>


<!-- Services -->
<a id="services" class="anchor"></a>
<h2>Services</h2>
<p>Journal Reviewer:  </p>
<font size="2"> 
<ul>
<li>IEEE Transactions on Medical Imaging (TMI)</li>
<li>IEEE Transactions on Communications (TCOM)</li>
<li>Knowledge Based Systems (KBS)</li>
</ul>
</font>


<p>Conference Reviewer: </p>
<font size="2"> 
<ul>
<li>IEEE International Conference on Computer Vision and Pattern Recognition (CVPR)</li>
<li>IEEE International Conference on Computer Vision (ICCV)</li>
<li>European Conference on Computer Vision (ECCV)</li>
<li>Association for the Advancement of Artificial Intelligence (AAAI)</li>>
<li>International Joint Conference on Artificial Intelligence (IJCAI) (Outstanding SPC for IJCAI2019)</li>
<li>International Conference on Medical Image Computing and Computer Assisted Intervention (MICCAI)</li>

</ul>
</font>

<div id="footer">
<div id="footer-text">
<!--
All Rights Reserved. Part of page is generated by <a href="http://jemdoc.jaboc.net/">jemdoc</a>.
-->

</div>
</div>
<a href="https://clustrmaps.com/site/1b743"  title="Visit tracker"><img src="//www.clustrmaps.com/map_v2.png?d=7HOnPG-tgP2NBIq9v142wI5iM0mQ3OwnnIRnYxx5SdI&cl=ffffff" width=1pt height=1pt/></a>
</body>
</html>
